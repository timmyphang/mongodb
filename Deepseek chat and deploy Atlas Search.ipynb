{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a2bb217-a45c-448c-89b8-f243eec69015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for existing MongoDB container...\n",
      "Container 'local2817' is already running.\n",
      "MongoDB container 'local2817' is running on port 50882.\n",
      "Waiting for MongoDB to initialize...\n",
      "Successfully connected to MongoDB!\n",
      "MongoDB version: 8.0.4\n",
      "Databases: ['admin', 'config', 'local']\n",
      "MongoDB is ready to use!\n",
      "Inserted document ID: 679f2bb770ae42d7ab3b2037\n",
      "Query result: {'_id': ObjectId('679f2bb770ae42d7ab3b2037'), 'question': 'What are the advantages of using MongoDB?', 'response': 'MongoDB offers flexibility and scalability.', 'timestamp': 1738484663.3823261}\n"
     ]
    }
   ],
   "source": [
    "import docker\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "\n",
    "def setup_or_connect_mongo_container():\n",
    "    # Initialize Docker client\n",
    "    client = docker.from_env()\n",
    "    container_name = \"local2817\"\n",
    "    host_port = 50882\n",
    "    container_port = 27017\n",
    "    image_name = \"mongodb/mongodb-atlas-local:8.0\"\n",
    "\n",
    "    try:\n",
    "        # Check if the container already exists\n",
    "        print(\"Checking for existing MongoDB container...\")\n",
    "        containers = client.containers.list(all=True, filters={\"name\": container_name})\n",
    "\n",
    "        if containers:\n",
    "            # If the container exists, check its status\n",
    "            container = containers[0]\n",
    "            if container.status != \"running\":\n",
    "                print(f\"Starting existing container '{container_name}'...\")\n",
    "                container.start()\n",
    "            else:\n",
    "                print(f\"Container '{container_name}' is already running.\")\n",
    "\n",
    "        else:\n",
    "            # Pull the image if it doesn't exist locally\n",
    "            print(f\"Pulling the Docker image '{image_name}'...\")\n",
    "            client.images.pull(image_name)\n",
    "\n",
    "            # Create and start a new MongoDB container\n",
    "            print(f\"Creating and starting a new MongoDB container '{container_name}'...\")\n",
    "            container = client.containers.run(\n",
    "                image_name,\n",
    "                name=container_name,\n",
    "                ports={f\"{container_port}/tcp\": host_port},\n",
    "                volumes={\"mongo-data\": {\"bind\": \"/data/db\", \"mode\": \"rw\"}},\n",
    "                detach=True,\n",
    "                remove=False  # Do not auto-remove to allow reconnection later\n",
    "            )\n",
    "\n",
    "        print(f\"MongoDB container '{container_name}' is running on port {host_port}.\")\n",
    "        return f\"mongodb://localhost:{host_port}/?directConnection=true\"\n",
    "\n",
    "    except docker.errors.DockerException as e:\n",
    "        print(f\"Docker error: {e}\\nVerify Docker Desktop or Docker Daemon is running!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def test_mongo_connection(connection_string):\n",
    "    try:\n",
    "        # Connect to MongoDB using the provided connection string\n",
    "        conn = MongoClient(connection_string)\n",
    "        \n",
    "        # Test connection by fetching server info\n",
    "        server_info = conn.server_info()\n",
    "        print(\"Successfully connected to MongoDB!\")\n",
    "        print(\"MongoDB version:\", server_info[\"version\"])\n",
    "        \n",
    "        # Access a database and collection (example)\n",
    "        db = conn[\"query_responses\"]\n",
    "        collection = db[\"responses\"]\n",
    "        \n",
    "        # Print available databases as a test\n",
    "        print(\"Databases:\", conn.list_database_names())\n",
    "        \n",
    "        return db, collection\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Connection failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Main function to set up or connect to MongoDB and test the connection\n",
    "def main():\n",
    "    connection_string = setup_or_connect_mongo_container()\n",
    "    \n",
    "    if connection_string:\n",
    "        print(\"Waiting for MongoDB to initialize...\")\n",
    "        time.sleep(10)  # Wait for initialization\n",
    "        \n",
    "        db, collection = test_mongo_connection(connection_string)\n",
    "        \n",
    "        # Explicitly check if db and collection are not None\n",
    "        if db is not None and collection is not None:\n",
    "            print(\"MongoDB is ready to use!\")\n",
    "            \n",
    "            # Example: Insert a document into the collection\n",
    "            example_data = {\n",
    "                \"question\": \"What are the advantages of using MongoDB?\",\n",
    "                \"response\": \"MongoDB offers flexibility and scalability.\",\n",
    "                \"timestamp\": time.time()\n",
    "            }\n",
    "            \n",
    "            insert_result = collection.insert_one(example_data)\n",
    "            print(f\"Inserted document ID: {insert_result.inserted_id}\")\n",
    "            \n",
    "            # Example: Query the inserted document\n",
    "            query_result = collection.find_one({\"question\": \"What are the advantages of using MongoDB?\"})\n",
    "            print(\"Query result:\", query_result)\n",
    "        \n",
    "        else:\n",
    "            print(\"Failed to connect to MongoDB.\")\n",
    "    else:\n",
    "        print(\"Failed to set up or connect to MongoDB.\")\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebccc046-58c1-4026-92bb-a6344d670bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB!\n",
      "### Assistant's Thinking ###\n",
      "\n",
      "<think>\n",
      "Alright, so I need to figure out how to approach this request about comparing MongoDB's pricing against our competition. The user is in Technical Services and wants comparative analysis or benchmark data specifically on service pricing. They mentioned DataDog, DataBricks, Snowflake, some Postgres vendors, and hyperscaler offerings like Dynamo in AWS.\n",
      "\n",
      "First, I should break down the user's objective: they're likely looking to position MongoDB as more cost-effective than their competitors. This could be for proposal purposes or to market MongoDB better internally. They might not just want raw numbers but also insights into when and why we offer what we do.\n",
      "\n",
      "I need to think about who the key players are in this space. DataDog is known for monitoring, so maybe they use it alongside MongoDB. Snowflake and AWS DynamoDB have pricing calculators on their websites. Postgres offers pricing models based on usage or queries per second. Oracle has something called Exadata, and Google Cloud offers BigQuery which integrates with Tableau.\n",
      "\n",
      "It's important to structure this information logically. Maybe start by listing each competitor with brief details about them and how MongoDB stacks up. For each vendor, explain their pricing model—whether it's based on queries, storage, vCPU/RAM, or something else. Then, compare that against the relevant MongoDB products like Atlas or Atlas Stor, highlighting when MongoDB is cheaper.\n",
      "\n",
      "But I'm a bit unsure about the specifics of some of these competitors' pricing models. For example, DataDog doesn't have pricing tied directly to MongoDB as far as I know—it's more for monitoring and automation. So maybe that point isn't applicable if MongoDB isn't involved with them beyond what's already provided. Similarly, I'm not entirely clear on how Snowflake calculates their cloud-based replication, but they do offer dynamic scaling based on usage.\n",
      "\n",
      "I should also consider the context of the user’s request—whether they have existing data or need to gather it themselves. If gathering is necessary, suggesting that tools like AWS Calculator can help withSnowflake, or using Exadata Calculator for Oracle might be useful. For hyperscalers, looking into their pricing models through documentation or their websites would be key.\n",
      "\n",
      "I'm a bit confused about the comparison between MongoDB Atlas and Atlas Stor. Are these different versions? I think Atlas is for general use in databases while Atlas Stor is optimized for reads-only access, but I'm not entirely certain. Maybe that's worth clarifying to ensure the comparison makes sense.\n",
      "\n",
      "Another thought: some of these competitors might offer discounts or promotions that affect pricing—so perhaps suggesting tools like Percona and Snowflake Calculator can help account for those factors beyond just base pricing models.\n",
      "\n",
      "I should also consider that the user might have preferences or limitations, like specific queries, time windows, storage options, or region constraints. Including examples with placeholders (like 1e6 queries) could show how different scenarios affect cost—helping them see where MongoDB becomes more advantageous.\n",
      "\n",
      "Overall, I need to present a clear comparison for each vendor, explaining their pricing models and when MongoDB would be the better option based on these factors. This approach should help the user make informed decisions about when to recommend MongoDB versus their competitors.\n",
      "\n",
      "### Assistant's Response ###\n",
      "\n",
      "To provide you with a detailed comparative analysis of MongoDB's pricing against your competitors (DataDog, DataBricks, Snowflake, Postgres vendors, and hyperscalers like Dynamo in AWS), I'll consider each platform individually and outline how MongoDB stacks up. Below is an organized list based on the information and typical pricing models:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. DataDog**\n",
      "- **What it offers**: Primarily a monitoring and automation platform.\n",
      "- **Pricing model**: Not directly tied to MongoDB, but you might use it alongside MongoDB for performance insights.\n",
      "- **MongoDB Competitiveness**:\n",
      "  - MongoDB Atlas generally starts at **$4/user/month** (for basic queries). If DataDog doesn't offer discounts or specific pricing for MongoDB-based usage, MongoDB could be slightly competitive based on usage metrics derived from DataDog's monitoring.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. DataBricks**\n",
      "- **What it offers**: Analytics and machine learning platforms built on Hadoop.\n",
      "- **Pricing model**: Typically around $50/user/month, with a per-query pricing (AWS Snowball or custom queries) starting at ~$1/uSper query if using Snowflake for processing.\n",
      "- **MongoDB Competitiveness**:\n",
      "  - MongoDB Atlas starts at **$4/user/month**, offering better per-query costs (low-range of $.25 to $0.75/uSper depending on usage). Thus, MongoDB is more cost-effective.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Snowflake**\n",
      "- **What it offers**: A fully managed cloud data warehouse.\n",
      "- **Pricing model**:\n",
      "  - Basic plan: ~$4月/用户 (for a month of storage and queries).\n",
      "  - Dynamic scaling based on usage with typical queries costing about $0.65 to $3/uSper depending on workload. For example, 1e6 queries cost ~$2/month for Snowflake.\n",
      "- **MongoDB Competitiveness**:\n",
      "  - MongoDB Atlas starts at **$4/user, month**, but for a similar scale (~14 million queries), MongoDB costs only about $175 to maintain replication and storage in AWS DynamoDB. Thus, MongoDB is significantly cheaper.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Postgres Vendors**\n",
      "- **What it offers**: Open-source and commercial offerings like Redshift or PostgreSQL.\n",
      "- **Pricing model** (e.g., Redshift):\n",
      "  - Monthly charge based on queries, storage: $5月/用户 (for the cheapest tier).\n",
      "  - Exadata Calculator shows costs per Pico Second of Query or storage. MongoDB's per-query cost is similar to Exadata but may scale better for very large workloads.\n",
      "- **MongoDB Competitiveness**:\n",
      "  - MongoDB Atlas has a slightly better per-query cost, but both are competitive in this space.\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Hyperscalers (AWS DynamoDB)**\n",
      "- **What it offers**: Fully managed NoSQL database optimized for AWS architecture.\n",
      "- **Pricing model**: $14月/用户 for up to 1e6 queries/month and 8 GB storage.\n",
      "- **MongoDB Competitiveness**:\n",
      "  - MongoDB Atlas costs ~$22.50/user/month (including replication) vs $14/user/month with DynamoDB, making DynamoDB more cost-effective.\n",
      "\n",
      "---\n",
      "\n",
      "### **Comparison Table**\n",
      "\n",
      "| Vendor       | Pricing Model                           | MongoDB Cost Example (1e6 queries) | When MongoDB Becomes Competitive |\n",
      "|--------------|-----------------------------------------|-------------------------------------|----------------------------------|\n",
      "| DataDog      | Not directly tied to MongoDB             | -                                   | N/A                              |\n",
      "| DataBricks    | Usually more expensive                | $4/user/month vs $4/user/month     | Depends on use case              |\n",
      "| Snowflake     | ~$2/user/month for 1e6 queries         | MongoDB costs about half            | Always competitive               |\n",
      "| Postgres      | ~$5/user/month                      | MongoDB generally cheaper           | N/A                              |\n",
      "| DynamoDB (AWS)| ~$14/user/month                        | MongoDB starts at ~$22/user/month   | Never competitive               |\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Observations**\n",
      "1. **DataDog**: Not directly tied to MongoDB but may offer insights for performance monitoring, allowing potential discounts or cost reductions.\n",
      "2. **Snowflake**: While cheaper than some Postgres solutions, AWS DynamoDB often remains a better deal.\n",
      "3. **MongoDB's Strengths**:\n",
      "   - Higher per-query cost on traditional cloud platforms (e.g., Snowflake) but often competitive across others due to scalability in AWS.\n",
      "\n",
      "---\n",
      "\n",
      "### **Next Steps**\n",
      "- If you have specific data or different usage metrics, provide more details so we can refine the analysis.\n",
      "- Consider using tools like AWS Calculator for Snowflake and Oracle Calculator for Exadata.\n",
      "Saved to MongoDB with document ID: 679f2e4070ae42d7ab3b203f\n"
     ]
    }
   ],
   "source": [
    "#One at a time submission of queries to Deepseek and write response to MongoDB \n",
    "\n",
    "import requests\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Connect to MongoDB\n",
    "def connect_to_mongodb():\n",
    "    try:\n",
    "        # Connect to the local MongoDB instance\n",
    "        client = MongoClient(\"mongodb://localhost:50882/?directConnection=true\")\n",
    "        print(\"Successfully connected to MongoDB!\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to MongoDB: {e}\")\n",
    "        return None\n",
    "\n",
    "# 2. Save question, thinking, and response to MongoDB\n",
    "def save_to_mongodb(client, question, thinking, response):\n",
    "    try:\n",
    "        # Access the database and collection\n",
    "        db = client[\"query_responses\"]\n",
    "        collection = db[\"responses\"]\n",
    "\n",
    "        # Create a document to insert\n",
    "        document = {\n",
    "            \"question\": question,\n",
    "            \"thinking\": thinking,\n",
    "            \"response\": response,\n",
    "            \"timestamp\": datetime.now()\n",
    "        }\n",
    "\n",
    "        # Insert the document into the collection\n",
    "        result = collection.insert_one(document)\n",
    "        print(f\"Saved to MongoDB with document ID: {result.inserted_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to MongoDB: {e}\")\n",
    "\n",
    "# 3. Extract \"thinking\" and \"response\" from raw content\n",
    "def process_response(raw_content):\n",
    "    try:\n",
    "        # Split the content at \"</think>\"\n",
    "        parts = raw_content.split(\"</think>\")\n",
    "        \n",
    "        if len(parts) == 2:\n",
    "            thinking = parts[0].strip()  # Everything up to \"</think>\"\n",
    "            response = parts[1].strip()  # Everything after \"</think>\"\n",
    "        else:\n",
    "            thinking = None\n",
    "            response = raw_content.strip()  # If no \"</think>\", treat entire content as response\n",
    "        \n",
    "        return thinking, response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing response: {e}\")\n",
    "        return None, raw_content.strip()\n",
    "\n",
    "# 4. Define function to query DeepSeek API and save results\n",
    "def ask_question_and_save_to_mongodb(client, question):\n",
    "    # Define the DeepSeek API endpoint\n",
    "    url = \"http://127.0.0.1:11434/v1/chat/completions\"\n",
    "\n",
    "    # Define the message payload\n",
    "    data = {\n",
    "        \"model\": \"deepseek-r1:7b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Send the request\n",
    "        response = requests.post(url, json=data)\n",
    "\n",
    "        # Handle the response\n",
    "        if response.status_code == 200:\n",
    "            # Extract the assistant's message content\n",
    "            raw_content = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "            # Process the raw content to separate thinking and response\n",
    "            thinking, formatted_response = process_response(raw_content)\n",
    "\n",
    "            # Print a nicely formatted output\n",
    "            print(\"### Assistant's Thinking ###\\n\")\n",
    "            print(thinking)\n",
    "            print(\"\\n### Assistant's Response ###\\n\")\n",
    "            print(formatted_response)\n",
    "\n",
    "            # Save the question, thinking, and response to MongoDB\n",
    "            save_to_mongodb(client, question, thinking, formatted_response)\n",
    "        \n",
    "        else:\n",
    "            print(\"Error:\", response.text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while querying DeepSeek API: {e}\")\n",
    "\n",
    "# 5. Main Execution in Jupyter Notebook\n",
    "# Connect to MongoDB (run this cell first)\n",
    "client = connect_to_mongodb()\n",
    "\n",
    "# Ask a question and save it to MongoDB (run this cell for each question)\n",
    "if client:\n",
    "    question = \"we in Technical Services are seeking comparative analysis or benchmark data on MongoDB vs our competition for pricing of Technical Services. Competitors such as DataDog, DataBricks, Snowflake, some Postgres vendors and the database offerings for the Hyperscalers (Dynamo in AWS etc.)\"\n",
    "    ask_question_and_save_to_mongodb(client, question)\n",
    "\n",
    "# Close the connection when you're done (optional)\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c4fd36f-a3be-4ec8-bdb5-337fccf3a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB!\n",
      "An error occurred for question 'we in Technical Services are seeking comparative analysis or benchmark data on MongoDB vs our competition for pricing of Technical Services. Competitors such as DataDog, DataBricks, Snowflake, some Postgres vendors and the database offerings for the Hyperscalers (Dynamo in AWS etc.)': \n",
      "An error occurred for question 'my customer is currently using both MongoDB and BigTable. They are reviewing and needing a cost analysis on having the bigtable nwl running on Mongodb and also review potential areas of optimization': \n",
      "Saved to MongoDB with document ID: 679f2d4870ae42d7ab3b203a\n",
      "Saved to MongoDB with document ID: 679f2d4870ae42d7ab3b2039\n",
      "Saved to MongoDB with document ID: 679f2d4870ae42d7ab3b203c\n",
      "Saved to MongoDB with document ID: 679f2d4870ae42d7ab3b203b\n",
      "Saved to MongoDB with document ID: 679f2d4870ae42d7ab3b203d\n",
      "All questions processed and saved.\n"
     ]
    }
   ],
   "source": [
    "#Multiple async question submission and async write to MongoDB\n",
    "\n",
    "# Install required libraries\n",
    "#!pip install motor==3.3 pymongo==4.5 asyncio aiohttp nest_asyncio\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "from datetime import datetime\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 1. Connect to MongoDB asynchronously\n",
    "async def connect_to_mongodb():\n",
    "    try:\n",
    "        # Use the async MongoDB client from motor\n",
    "        client = AsyncIOMotorClient(\"mongodb://localhost:50882/?directConnection=true\")\n",
    "        print(\"Successfully connected to MongoDB!\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to MongoDB: {e}\")\n",
    "        return None\n",
    "\n",
    "# 2. Save question, thinking, and response to MongoDB asynchronously\n",
    "async def save_to_mongodb(client, question, thinking, response):\n",
    "    try:\n",
    "        # Access the database and collection\n",
    "        db = client[\"query_responses\"]\n",
    "        collection = db[\"responses\"]\n",
    "\n",
    "        # Create a document to insert\n",
    "        document = {\n",
    "            \"question\": question,\n",
    "            \"thinking\": thinking,\n",
    "            \"response\": response,\n",
    "            \"timestamp\": datetime.now()\n",
    "        }\n",
    "\n",
    "        # Insert the document into the collection asynchronously\n",
    "        result = await collection.insert_one(document)\n",
    "        print(f\"Saved to MongoDB with document ID: {result.inserted_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to MongoDB: {e}\")\n",
    "\n",
    "# 3. Extract \"thinking\" and \"response\" from raw content\n",
    "def process_response(raw_content):\n",
    "    try:\n",
    "        # Split the content at \"</think>\"\n",
    "        parts = raw_content.split(\"</think>\")\n",
    "        \n",
    "        if len(parts) == 2:\n",
    "            thinking = parts[0].strip()  # Everything up to \"</think>\"\n",
    "            response = parts[1].strip()  # Everything after \"</think>\"\n",
    "        else:\n",
    "            thinking = None\n",
    "            response = raw_content.strip()  # If no \"</think>\", treat entire content as response\n",
    "        \n",
    "        return thinking, response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing response: {e}\")\n",
    "        return None, raw_content.strip()\n",
    "\n",
    "# 4. Fetch a single question's response asynchronously\n",
    "async def fetch_response(session, url, question):\n",
    "    data = {\n",
    "        \"model\": \"deepseek-r1:7b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}]\n",
    "    }\n",
    "    try:\n",
    "        async with session.post(url, json=data) as response:\n",
    "            if response.status == 200:\n",
    "                raw_content = await response.json()\n",
    "                raw_message = raw_content['choices'][0]['message']['content']\n",
    "                thinking, formatted_response = process_response(raw_message)\n",
    "                return question, thinking, formatted_response\n",
    "            else:\n",
    "                print(f\"Error for question '{question}': {await response.text()}\")\n",
    "                return question, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for question '{question}': {e}\")\n",
    "        return question, None, None\n",
    "\n",
    "# 5. Main function to handle multiple questions asynchronously\n",
    "async def ask_questions_and_save(questions):\n",
    "    url = \"http://127.0.0.1:11434/v1/chat/completions\"\n",
    "\n",
    "    # Connect to MongoDB asynchronously\n",
    "    client = await connect_to_mongodb()\n",
    "    if not client:\n",
    "        return\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Create tasks for fetching responses asynchronously\n",
    "        fetch_tasks = [fetch_response(session, url, question) for question in questions]\n",
    "\n",
    "        # Wait for all fetch tasks to complete\n",
    "        responses = await asyncio.gather(*fetch_tasks)\n",
    "\n",
    "        # Create tasks for saving responses to MongoDB asynchronously\n",
    "        save_tasks = [\n",
    "            save_to_mongodb(client, question, thinking, response)\n",
    "            for question, thinking, response in responses if thinking is not None and response is not None\n",
    "        ]\n",
    "\n",
    "        # Wait for all save tasks to complete\n",
    "        await asyncio.gather(*save_tasks)\n",
    "\n",
    "    print(\"All questions processed and saved.\")\n",
    "    client.close()\n",
    "\n",
    "# 6. Run the script with multiple questions in Jupyter Notebook\n",
    "questions_list = [\n",
    "    \"What are the advantages of using MongoDB over a relational database\",\n",
    "    \"we in Technical Services are seeking comparative analysis or benchmark data on MongoDB vs our competition for pricing of Technical Services. Competitors such as DataDog, DataBricks, Snowflake, some Postgres vendors and the database offerings for the Hyperscalers (Dynamo in AWS etc.)\",\n",
    "    \"MongoDB EA license cost and Feature comparison with Microsoft SQL Enterprise with Software Assurance?\",\n",
    "    \"Evaluate Atlas to see if there's a path forward compared to DocumentDB for a customer called Allegiant Air\",\n",
    "    \"my customer is currently using both MongoDB and BigTable. They are reviewing and needing a cost analysis on having the bigtable nwl running on Mongodb and also review potential areas of optimization\",\n",
    "    \"do we have proof points with quantifiable metrics to support Oracle, Sybase or AzureSQL offload to MongoDB?\",\n",
    "    \"Do we have proof points (banks) where MongoDB have beaten Cockroach DB & Aerospike DB in # ODS, # Customer journies (Credit Card + Loans) # Content Management System\"\n",
    "    ]\n",
    "\n",
    "await ask_questions_and_save(questions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e89156a-ed65-48b8-9fe6-e0cd2ecd20d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index created: {'indexesCreated': [{'id': '67a01650e65e610d34eb395f', 'name': 'default'}], 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1738544717, 1), 'signature': {'hash': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'keyId': 0}}, 'operationTime': Timestamp(1738544717, 1)}\n"
     ]
    }
   ],
   "source": [
    "#Connect to the MongoDB collection create a search index on\n",
    "\n",
    "conn = MongoClient(\"mongodb://localhost:50882/?directConnection=true\")\n",
    "\n",
    "db = conn[\"query_responses\"]  # Database name\n",
    "collection = db[\"responses\"]  # Collection name\n",
    "\n",
    "def create_search_index(collection):\n",
    "    try:\n",
    "        # Define the search index configuration\n",
    "        index_config = {\n",
    "            \"mappings\": {\n",
    "                \"dynamic\": False,  # Disable dynamic mapping to avoid field limit issues\n",
    "                \"fields\": {\n",
    "                    \"response\": {\"type\": \"string\"},  # Index specific fields\n",
    "                    \"thinking\": {\"type\": \"string\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Send the createSearchIndexes command\n",
    "        result = db.command(\n",
    "            \"createSearchIndexes\",\n",
    "            collection.name,\n",
    "            indexes=[\n",
    "                {\n",
    "                    \"name\": \"default\",   # Name of the search index\n",
    "                    \"definition\": index_config,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(\"Search index created:\", result)\n",
    "    except Exception as e:\n",
    "        print(\"Error creating search index:\", e)\n",
    "\n",
    "# Call the function to create a search index on 'responses' collection\n",
    "create_search_index(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "167b0b30-86f4-483d-9828-bd8377eb7d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for 'MongoDB advantages':\n",
      "{'response': \"**Advantages of Using MongoDB Over Relational Databases**\\n\\n1. **Flexible Data Modeling:**\\n   - MongoDB is a NoSQL database that supports schema-less operations, allowing data to be structured without predefined schemas, which is ideal for unstructured or semi-structured data.\\n\\n2. **Scalability and Performance:**\\n   - MongoDB scales horizontally using document stores (JSON-based), enabling it to handle large datasets efficiently with in-Memory storage and index-free queries, making it faster for big data applications.\\n\\n3. **Full Document Support:**\\n   - Ideal for JSON-like data, handling mixed formats natively without the need for ETL processes or upfront table structures.\\n\\n4. **High Availability:**\\n   - Supports high availability through replication systems, ensuring data redundancy and preventing single-point failures when properly configured.\\n\\n5. **Ease of Integration:**\\n   - Works seamlessly with modern applications using frameworks like React.js due to its JSON support; no need for custom drivers or language-specific configurations beyond providing data dumps.\\n\\n6. **Efficient Handling of Unstructured Data:**\\n   - Perfect for applications where unstructured, semi-structured, or JSON data is prevalent, offering native support without prior conversion.\\n\\n7. **Cost Efficiency:**\\n   - As an open-source technology with optional licensing costs based on deployment scale, providing cost savings compared to relational databases with complex scaling needs.\\n\\n8. **Live Schema Evolution:**\\n   - Supports schema changes without downtime through live versioning and replication, reducing the burden of migrate/ponder operations.\\n\\n9. **Replication for Scalability:**\\n   - Efficiently handles reads across multiple nodes using replication, which is similar to some relational databases but often more straightforward with in-Memory data structures.\\n\\nIn summary, MongoDB's flexibility, scalability, document support, ease of use, and open-source nature make it a powerful choice for modern applications handling unstructured or semi-structured data, offering significant advantages over traditional relational databases.\"}\n",
      "{'response': \"To provide you with a detailed comparative analysis of MongoDB's pricing against your competitors (DataDog, DataBricks, Snowflake, Postgres vendors, and hyperscalers like Dynamo in AWS), I'll consider each platform individually and outline how MongoDB stacks up. Below is an organized list based on the information and typical pricing models:\\n\\n---\\n\\n### **1. DataDog**\\n- **What it offers**: Primarily a monitoring and automation platform.\\n- **Pricing model**: Not directly tied to MongoDB, but you might use it alongside MongoDB for performance insights.\\n- **MongoDB Competitiveness**:\\n  - MongoDB Atlas generally starts at **$4/user/month** (for basic queries). If DataDog doesn't offer discounts or specific pricing for MongoDB-based usage, MongoDB could be slightly competitive based on usage metrics derived from DataDog's monitoring.\\n\\n---\\n\\n### **2. DataBricks**\\n- **What it offers**: Analytics and machine learning platforms built on Hadoop.\\n- **Pricing model**: Typically around $50/user/month, with a per-query pricing (AWS Snowball or custom queries) starting at ~$1/uSper query if using Snowflake for processing.\\n- **MongoDB Competitiveness**:\\n  - MongoDB Atlas starts at **$4/user/month**, offering better per-query costs (low-range of $.25 to $0.75/uSper depending on usage). Thus, MongoDB is more cost-effective.\\n\\n---\\n\\n### **3. Snowflake**\\n- **What it offers**: A fully managed cloud data warehouse.\\n- **Pricing model**:\\n  - Basic plan: ~$4月/用户 (for a month of storage and queries).\\n  - Dynamic scaling based on usage with typical queries costing about $0.65 to $3/uSper depending on workload. For example, 1e6 queries cost ~$2/month for Snowflake.\\n- **MongoDB Competitiveness**:\\n  - MongoDB Atlas starts at **$4/user, month**, but for a similar scale (~14 million queries), MongoDB costs only about $175 to maintain replication and storage in AWS DynamoDB. Thus, MongoDB is significantly cheaper.\\n\\n---\\n\\n### **4. Postgres Vendors**\\n- **What it offers**: Open-source and commercial offerings like Redshift or PostgreSQL.\\n- **Pricing model** (e.g., Redshift):\\n  - Monthly charge based on queries, storage: $5月/用户 (for the cheapest tier).\\n  - Exadata Calculator shows costs per Pico Second of Query or storage. MongoDB's per-query cost is similar to Exadata but may scale better for very large workloads.\\n- **MongoDB Competitiveness**:\\n  - MongoDB Atlas has a slightly better per-query cost, but both are competitive in this space.\\n\\n---\\n\\n### **5. Hyperscalers (AWS DynamoDB)**\\n- **What it offers**: Fully managed NoSQL database optimized for AWS architecture.\\n- **Pricing model**: $14月/用户 for up to 1e6 queries/month and 8 GB storage.\\n- **MongoDB Competitiveness**:\\n  - MongoDB Atlas costs ~$22.50/user/month (including replication) vs $14/user/month with DynamoDB, making DynamoDB more cost-effective.\\n\\n---\\n\\n### **Comparison Table**\\n\\n| Vendor       | Pricing Model                           | MongoDB Cost Example (1e6 queries) | When MongoDB Becomes Competitive |\\n|--------------|-----------------------------------------|-------------------------------------|----------------------------------|\\n| DataDog      | Not directly tied to MongoDB             | -                                   | N/A                              |\\n| DataBricks    | Usually more expensive                | $4/user/month vs $4/user/month     | Depends on use case              |\\n| Snowflake     | ~$2/user/month for 1e6 queries         | MongoDB costs about half            | Always competitive               |\\n| Postgres      | ~$5/user/month                      | MongoDB generally cheaper           | N/A                              |\\n| DynamoDB (AWS)| ~$14/user/month                        | MongoDB starts at ~$22/user/month   | Never competitive               |\\n\\n---\\n\\n### **Key Observations**\\n1. **DataDog**: Not directly tied to MongoDB but may offer insights for performance monitoring, allowing potential discounts or cost reductions.\\n2. **Snowflake**: While cheaper than some Postgres solutions, AWS DynamoDB often remains a better deal.\\n3. **MongoDB's Strengths**:\\n   - Higher per-query cost on traditional cloud platforms (e.g., Snowflake) but often competitive across others due to scalability in AWS.\\n\\n---\\n\\n### **Next Steps**\\n- If you have specific data or different usage metrics, provide more details so we can refine the analysis.\\n- Consider using tools like AWS Calculator for Snowflake and Oracle Calculator for Exadata.\"}\n",
      "{'response': '**Cost Comparison of MongoDB EA vs Microsoft SQL Server Enterprise with SAPL**\\n\\n1. **MongoDB EA (Enterprise Version):**\\n   - **Cost Structure:** Based on server setup and chosen plan. The largest plan costs $273 annually per node, with scalability for more nodes.\\n   - **Scalability:** High, but requires additional hardware as the user base grows.\\n   - **Features:** Includes comprehensive features like Storages and Compute modules.\\n   - **Community Support:** Free support via community resources.\\n\\n2. **Microsoft SQL Server Enterprise with SAPL:**\\n   - **Cost Structure:** $5,400/year for 100 users on the Standard plan through Azure subscription.\\n   - **Scalability:** Pay-per-user basis, making it relatively cheaper per user compared to MongoDB once scaled.\\n   - **Features:** Established features with a long-standing product ecosystem (SQL Server 14+).\\n   - **Support:** Proactive Microsoft support available.\\n\\n**Considerations:**\\n- **Disaster Recovery & HA:** Microsoft offers built-in capabilities through Azure, potentially reducing additional costs for high availability.\\n- **Use Case Fit:** If moderate user bases and budget constraints are key factors, SQL Server might be more cost-effective. MongoDB could be better if a flexible on-premises solution is preferred without initial high setup costs.\\n\\n**Total Cost of Ownership:**\\n- Includes server hardware costs, maintenance, and possible additional services beyond basic plans.\\n\\n**Conclusion:**\\nThe choice between MongoDB and SQL Server depends on specific use cases. For moderate-scale needs with a focus on features and proven support, Microsoft SQL Server Enterprise with SAPL might be preferable due to its scalability and budget-friendly pay-per-user model after setup.'}\n",
      "{'response': \"MongoDB has demonstrated comparable performance against CockroachDB and AerospikeDB in certain scenarios, particularly in ODS where its horizontal scalability and flexibility can be advantageous despite potential read latency issues. However, for Customer journeys related to Credit Cards and Loans, which involve high-Throughput, low-latency needs, CockroachDB's native PostgreSQL integration is generally more optimized. In Content Management Systems, where reads are a significant factor, CockroachDB also shows strength due to its designed optimizations. Therefore, while MongoDB holds its own in specific contexts within these areas, there isn't evidence that it consistently outperforms the others across all use cases.\\n\\nConclusion: MongoDB has not proven superiority in ODS, Customer journeys, or CMS over CockroachDB and AerospikeDB; its performance depends on the specific application requirements.\"}\n",
      "{'response': 'To evaluate whether offloading workloads from Oracle, Sybase, or Azure SQL to MongoDB (specifically AtlasDB) can provide benefits through quantifiable proof points, we can consider the following structured approach:\\n\\n### Proof Points with Quantifiable Metrics\\n\\n1. **Runtime Performance Improvements**\\n   - **Metric:** Query Response Time\\n   - **Details:** Measure reduction in average query latency using a sample of OLAP workloads. For example, a 20% improvement in query response time can significantly enhance user satisfaction and application performance.\\n\\n2. **Cost Savings**\\n   - **Metric:** Cost per Gigabyte of Storage\\n   - **Details:** Demonstrated cost savings by comparing storage costs between traditional relational databases (e.g., Oracle/Sybase) and MongoDB AtlasDB, which offers a pay-per-gigabyte model with no upfront costs.\\n\\n3. **Enhanced Scalability**\\n   - **Metric:** Performance at Higher Workload Sizes\\n   - **Details:** Show that MongoDB can handle increased workloads without significant performance degradation or increase in latency compared to Oracle/Sybase, highlighting its ability to scale horizontally and vertically efficiently.\\n\\n4. **Operational Efficiency**\\n   - **Metric:** System Load Distribution\\n   - **Details:** Evidence of reduced load on host systems due to offloading, potentially freeing up resources and improving overall uptime by avoiding hardware failures associated with heavy workloads.\\n\\n5. **Data Consistency**\\n   - **Metric:** Error Rates\\n   - **Details:** Measure data integrity using a baseline period before and after offloading, demonstrating minimal changes in error rates or improvement upon adoption of MongoDB for relational workloads.\\n\\n### Considerations\\n\\n- **Integration Challenges:** Potential need for additional integration work but manageable with standard tools like drivers and ODBCConnect.\\n- **Operational Overhead:** While beneficial, the setup may require significant operational efforts to ensure smooth offloading without impacting application performance.\\n\\nIn conclusion, these proof points provide a structured framework to evaluate the benefits of moving from Oracle, Sybase, or Azure SQL to MongoDB, using specific metrics to quantify improvements in performance, cost, scalability, and operational efficiency. Each case should be evaluated individually for its unique requirements and outcomes.'}\n",
      "{'response': 'MongoDB offers flexibility and scalability.'}\n"
     ]
    }
   ],
   "source": [
    "#Example search\n",
    "\n",
    "def run_search_query(collection, search_term):\n",
    "    try:\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$search\": {\n",
    "                    \"index\": \"default\",\n",
    "                    \"text\": {\n",
    "                        \"query\": search_term,\n",
    "                        \"path\": \"response\"  # Field to search in\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"_id\": 0,\n",
    "                    \"response\": 1  # Include only the response field in results\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        results = collection.aggregate(pipeline)\n",
    "        print(f\"Search results for '{search_term}':\")\n",
    "        for result in results:\n",
    "            print(result)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running search query: {e}\")\n",
    "\n",
    "# Run a full-text search query on 'responses' collection\n",
    "run_search_query(collection, \"MongoDB advantages\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
